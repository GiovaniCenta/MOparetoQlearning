# Multiobjective Reinforcement Learning using Pareto dominating Policies in Deep Sea Treasure Problem

This repository contains a Multi-objective Q-Learning implementation of the well know Deep Sea Treasure problem using Pareto Dominating Policies.
Our objectives in this implementation are the treasure value and the time penalty, our agent is the submarine. 
All the environment is given to us by the pygame library, the OpenAI's Gym library, and Lucas Alegre's MO-Gym repository.

This reproduces the following algorithms:

* ** Algorithm 4 - Pareto Q-learning algorithm in  Van Moffaert Multi-Objective Reinforcement Learning using Sets of Pareto Dominating Policies paper[1]


## Requirements

Before you begin, ensure you have met the following requirements:

* Python v3.7
* NumPy v1.15.1
* SciPy v1.1.0
* MatPlotLib v2.2.3
* SymPy v1.2
* pygmo
* pygame
* OpenAI Gym Library
* MO-Gym Environment [https://github.com/LucasAlegre/mo-gym]

Older versions of the above items may not be fully compatible with our code.

## Usage

Simply run the following command:
```bash
python deepst.py
```

## Contributors

Thanks to the following people who have contributed to this project:

* [Giovani da Silva](https://github.com/giovanicenta)
* [Mateus Salvi](https://github.com/mateusalvi)



## License

This project uses the following license: [MIT](https://github.com/goramos/marl-route-choice/blob/f5a47bc5c6a791bf3d2eed48e13b5ca2a28fba5a/LICENSE).
